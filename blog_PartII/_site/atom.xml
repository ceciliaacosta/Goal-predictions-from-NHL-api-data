<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Projet IFT6758 Blog partie II</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <link href="http://localhost:4000/"/>
 <updated>2024-01-15T15:20:28-05:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>Fawzi Fatima Zahra, Frank Sherif, Francis, Frida-Cecilia</name>
   <email></email>
 </author>

 
 <entry>
   <title>milestone2</title>
   <link href="http://localhost:4000/2023/11/13/milestone2/"/>
   <updated>2023-11-13T00:00:00-05:00</updated>
   <id>http://localhost:4000/2023/11/13/milestone2</id>
   <content type="html">&lt;h2 id=&quot;partie-2--ingénierie-des-caractéristiques-i&quot;&gt;Partie 2:  Ingénierie des caractéristiques I&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Question 1&lt;/strong&gt;&lt;br /&gt;
&lt;img src=&quot;../assets/Histogram_Distance.png&quot; alt=&quot;Histogramme des tirs et des buts par distance du filet &quot; /&gt;&lt;/p&gt;

&lt;p&gt;Sur cet histogramme, il est possible de réaliser que la majorité des tirs et des buts proviennent d’une distance circonscrite entre 0 et 60 pieds. Il semble y avoir une distance où il y a plus de tirs et plus de but dans les environs de 10-15 pieds, puis plus on s’éloigne de cette distance, plus le nombre de buts diminue.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Histogram_Angle.png&quot; alt=&quot;Histogramme des tirs et des buts par angle par rapport au but&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Sur cet histogramme, en un coup d’œil, nous pouvons déceler qu’il semble y avoir 3 pics pour les sites de prédilection pour les tirs, soit 90, 60 et 45 degrés. À garder en tête que nous avons fait une échelle de 0 à 90 donc les valeurs inférieures à 90 représentent les valeurs pour les deux côtés de la patinoire. Nous avons préféré ce mode de représentation parce que les angles opposés (par exemple 45 et 135) représentent la même visualisation du filet et l’aire du filet disponible pour le tir (avec ou sans gardien). Il est facile de voir que plus l’angle diminue à partir de 90 degré, plus le nombre de buts diminue. Plus il y a un angle, moins de filet disponible et visible pour un but est présent lorsqu’un gardien est positionné correctement.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/2DHistogram_Distance.png&quot; alt=&quot;Histogramme 2D démontrant le lien entre la distance et l’angle&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Il est possible de voir que la majorité des tirs sont produits le plus prêt du filet possible et à un angle se rapprochant le plus de 90 degré parce que ça semble être des caractéristiques liées au taux de succès pour marquer un but. Cependant, il faudra analyser plus parce que le taux de buts plus élevés avec ses caractéristiques pourraient être seulement dû à la fréquence plus augmentée de ces évènements.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Question 2&lt;/strong&gt;&lt;br /&gt;	
«««&amp;lt; HEAD&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/GoalRatebyDistanceBin.png&quot; alt=&quot;Histogramme du taux de buts par groupe de distance en pieds&quot; /&gt;			
&lt;img src=&quot;../assets/GoalRatebyDistanceBinExludEmptynet.png&quot; alt=&quot;Histogramme du taux de buts par groupe de distance en pieds&quot; /&gt;&lt;/p&gt;

&lt;p&gt;En regardant le taux de buts par groupe de distance en pieds, il est possible de voir une tendance que les tirs les plus dangereux semblent être ceux effectués près du filet. La recrudescence des buts à partir de la distance de 100 pieds est due aux buts dans les filets déserts et aux événements mal classés. Effectivement, comme peu de tirs sont effectués à cette distance quand le gardien en en position dans le but, le taux de buts à ces distances sont expliqués par les buts en filet désert. On peut réaliser dans la figure de droite en retirant ces buts que le taux de buts diminue plus on s’éloigne du filet.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/GoalRatebyAngleBin.png&quot; alt=&quot;Histogramme du taux de buts par angle par rapport au filet&quot; /&gt;&lt;/p&gt;

&lt;p&gt;En un simple coup d’œil, il est possible de voir que plus on s’éloigne de l’angle de 90 degré, moins les tirs sont efficaces pour marquer des buts comme le taux de buts diminue. Cependant, l’effet est moins marqué que celui de la distance et il y a un effet plateau entre 70 et 30 degrés où les taux sont similaires. À noter encore que les groupes d’angle sous les 90 degré représente les angles à gauche et à droite du gardien, alors l’importance d’être près du 90 degré ici est minimisée.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/EmptyNetvsNon-EmptyNet.png&quot; alt=&quot;Histogramme en transformation log des buts marqués en filet désert ou non&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ici, nous avons dû faire une transformation en base logarithmique pour mieux déceler et comparer les deux entités parce que la différence en termes de nombre d’événements entre les deux catégories est trop importante. Il est possible de voir que le nombre de buts en filet désert est assez constant à travers toutes les distances et dépasse le nombre de buts marqués avec un gardien présent à environ 70 pieds du filet. Il est possible de penser que les événements où un but est marqué à une distance plus grande que 100 pieds lorsque le gardien est présent sont rarissimes et qu’une partie d’entre eux ont des erreurs au niveau de l’enregistrement de leurs coordonnées dans le jeu de données initial.&lt;/p&gt;

&lt;p&gt;Pour identifier les événements qui étaient possiblement mal classés en termes de coordonnées, il suffisait d’utiliser l’intuition de nos connaissances de hockey et de celle acquise avec la visualisation des données en observant les buts réalisés avec un gardien présent à des distances plus hautes. Voici un exemple d’évènements repéré:	
0,2,2015-10-08T00:21:09Z,Toronto Maple Leafs,GOAL,-73.0,-1.0,Deflected,False,Power Play,James van Riemsdyk,Carey Price,2015020001,regular&lt;/p&gt;

&lt;p&gt;En 2015, en deuxième période, les Maple Leafs tiraient sur le but (89,0) et donc un tir dévié sur le power play provenait le plus probablement des coordonnées (73, -1). Comme on peut voir sur la photo prise d’une vidéo youtube d’un récapitulatif de la chaîne TVA sport, James van Riemsdyk est le joueur positionné directement devant le gardien Carey Price.&lt;/p&gt;

&lt;h2 id=&quot;partie-3-modèles-de-base&quot;&gt;Partie 3: Modèles de base&lt;/h2&gt;

&lt;p&gt;La précision du modèle est de 90% d’accuracy pour un modèle de régression logistique de base ce qui me semble trop élevé pour un classifieur de base basé seulement sur la distance. Un problème que je vois pourrait être que le classifieur ne fait qu’utiliser le taux de buts par distance, qui diminue plus la distance augmente, pour faire sa prédiction. Comme les buts sont relativement rares, le modèle n’a qu’à prédire légèrement plus de buts que le taux de buts par distance pour avoir une performance adéquate. Cependant, ce type de modèle, si utilisé sur d’autres données va faire des erreurs par exemple s’il y a un tir effectué de très loin vers un filet désert, des tirs de la ligne bleue lors d’avantage numérique, d’autant plus à 5 contre 3 etc. De plus, si on veut un modèle de plus en plus précis en analysant plus de données, la composante binaire nous intéresse moins que la probabilité que le tir soit un but.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Image1.png&quot; alt=&quot;ROC curves for all the models&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Il est possible de voir qu’entre les caractéristiques de distance et d’angle, celle de distance est plus discriminante pour savoir si un tir sera un but ou non. Nous avions déjà développé cette intuition en regardant les graphiques de taux de buts par distance et par angle. Après 90 degrés, le taux de buts par angle frappe un plateau de 70 à 30 degrés tandis que le taux de buts par distance ne cesse de diminuer plus la distance augmente. On peut voir que lorsqu’on combine l’angle et la distance, le modèle performe légèrement mieux en terme de discrimination.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Image2.png&quot; alt=&quot;Graphique du taux de buts par la probabilité du modèle en percentile&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Il est possible de voir encore une fois la même tendance, c’est-à-dire que la prédiction par le modèle est meilleure en termes de percentile en considérant le taux de but par distance que par angle pour les mêmes raisons qu’évoqué plus tôt. Encore une fois le modèle combiné performe légèrement mieux que celui de la distance seul.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Image3.png&quot; alt=&quot;Graphique du taux de buts par la probabilité du modèle en percentile&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Il est possible de voir encore une fois la même tendance, c’est-à-dire que la prédiction par le modèle est meilleure en termes de percentile en considérant le taux de but par distance que par angle pour les mêmes raisons qu’évoqué plus tôt. Encore une fois le modèle combiné performe légèrement mieux que celui de la distance seul. Le modèle par angle offre un performance légèrement meilleure que le modèle aléatoire de base.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Image4.png&quot; alt=&quot;Graphique du taux de buts par la probabilité du modèle en percentile&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On voit qu’ajouter une variable pour que notre modèle soit plus précis fonctionne. Cependant, comme nous n’avons que fait des modèles de bases, nous atteignons à peine le 0,4 de probabilité prédite moyenne avec notre meilleur modèle, soit celui de la distance et de l’angle combiné. Il faudra très probablement inclure plus de caractéristiques plus complexes dans les prochaines étapes du projet pour faire des modèles se rapprochant de la ligne de la calibration parfaite. 	
**Lien vers lien vers l’expérience qui stocke l’artefact DataFrame filtré pour le jeu spécifié:
&lt;a href=&quot;https://www.comet.com/francis75/nhl-project/ae00b99b5c464daba590a450f1c7441b&quot;&gt;LienExperiance&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;partie-4-ingénierie-des-caractéristiques-2&quot;&gt;Partie 4: Ingénierie des caractéristiques 2&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Liste des caractéristiques créés&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;game_seconds: Temps ecoulé depuis debut de la periode en secondes&lt;/li&gt;
  &lt;li&gt;about.period: Periode de jeu&lt;/li&gt;
  &lt;li&gt;shot_distance: Distance de tir&lt;/li&gt;
  &lt;li&gt;shot_angle: Angle de tir&lt;/li&gt;
  &lt;li&gt;last_event_type: Dernier événement avant celui actuel&lt;/li&gt;
  &lt;li&gt;last_event_y: Position y du dernier événement&lt;/li&gt;
  &lt;li&gt;last_event_x: Position x du dernier événement&lt;/li&gt;
  &lt;li&gt;time_since_last_event: Temps ecoulé depuis le dernier événement en secondes&lt;/li&gt;
  &lt;li&gt;distance_from_last_event: Distance séparant l’événement actuel de l’événement précedent&lt;/li&gt;
  &lt;li&gt;is_rebound: Valeur booléene indiquant si l’événement est un tir&lt;/li&gt;
  &lt;li&gt;shot_angle_change: Changement d’angle après un tir&lt;/li&gt;
  &lt;li&gt;event_speed: Vitesse de l’événement en cours&lt;/li&gt;
  &lt;li&gt;power_play_timer: Temps écoulé depuis le début du jeu de puissance en secondes&lt;/li&gt;
  &lt;li&gt;friendly skaters on ice: Le nombre de patineurs dans l’équipe actuelle&lt;/li&gt;
  &lt;li&gt;Opponents skaters on ice: Le nombre de patineurs de l’équipe adverse&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;**Lien vers lien vers l’expérience qui stocke l’artefact DataFrame filtré pour le jeu spécifié:
&lt;a href=&quot;https://www.comet.com/francis75/feature-engineering-data/cb1bac468bcd4f23b0f6fb8a25e17af2&quot;&gt;LienExperiance&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;partie-5--modèles-avancés&quot;&gt;Partie 5 : Modèles avancés&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Question 1:&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Dans cette partie, nous avons utilisé un modèle XGBoost avec les hyperparamètres par défaut qui sont définis par la bibliothèque XGBoost elle-même. Notez que nous utilisons XGBClassifier sans aucun argument, ce qui signifie que nous utilisons ceux par défaut.&lt;/p&gt;

&lt;p&gt;Les résultats trouvés :
&lt;img src=&quot;../assets/Q1XGBoost_Diag1.png&quot; alt=&quot;Receiver Operating Characteristic&quot; /&gt;
&lt;img src=&quot;../assets/Q1XGBoost_Diag2.png&quot; alt=&quot;Goal Rate vs. Shot Probability Model Percentile&quot; /&gt;
&lt;img src=&quot;../assets/Q1XGBoost_Diag3.png&quot; alt=&quot;shap_corr_matCumulative Goal Proportion vs. Shot Probability Model Percentilerix&quot; /&gt;
&lt;img src=&quot;../assets/Q1XGBoost_G4.png&quot; alt=&quot;Reliability Diagram (Calibration Curve) for Model&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On constate que qu’il n’y a pas de grande différence avec le modéle de regression logistique entrainé sur distance et angle. Mais au niveau du diagramme de fiabilité le modéle XGBoot qui oscille avant d’atteindre une valeur maximal.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.comet.com/francis75/nhl-projectvf/6b43466fcbd4409cb29e4a5f6f1a00bf&quot;&gt;ExperianceXGBoostPartI&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Question 2:&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Préparation des données :&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Encoder des variables catégorielles : L’algorithme XGBoost fonctionne avec des types numériques et vu que notre dataset contient des valeurs catégoriallles on a la techniques encodage leave on out.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Nettoyez les données :&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Pour les valeurs manquantes : nous avons eu le résultat suivant :&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                                              &lt;span class=&quot;n&quot;&gt;Missing&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Values&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;Percentage&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;distance_to_target_goal&lt;/span&gt;                                   &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.005559&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;angle_to_target_goal&lt;/span&gt;                                      &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.005559&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;about&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;period&lt;/span&gt;                                               &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;game_seconds&lt;/span&gt;                                               &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;coordinates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;                                             &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.005232&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;coordinates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;                                             &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.004905&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;prev_coordinates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;                                      &lt;span class=&quot;mi&quot;&gt;4157&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;1.359323&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;prev_coordinates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;                                      &lt;span class=&quot;mi&quot;&gt;4156&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;1.358996&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;time_since_last_event&lt;/span&gt;                                      &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;distance_from_last_event&lt;/span&gt;                                &lt;span class=&quot;mi&quot;&gt;4169&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;1.363247&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;is_rebound&lt;/span&gt;                                                 &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;shot_angle_change&lt;/span&gt;                                         &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.003270&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;event_speed&lt;/span&gt;                                            &lt;span class=&quot;mi&quot;&gt;10783&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;3.525999&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;shot_or_goal&lt;/span&gt;                                               &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;prev_result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eventTypeId_smoothed_loo_encoded&lt;/span&gt;               &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.000000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;secondaryType_smoothed_loo_encoded&lt;/span&gt;                 &lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.013734&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;On voit une variation de pourcentage des données manquantes pour les variables :
Les variables qui n’ont pas de valeurs manquantes :
shot_or_goal : Aucune valeur manquante (0%)
time_since_last_event : Aucune valeur manquante (0%)
is_rebound : Aucune valeur manquante (0%)
about.period : Aucune valeur manquante (0%)
game_seconds : Aucune valeur manquante (0%)
prev_result.eventTypeId_smoothed_loo_encoded : Aucune valeur manquante (0%)&lt;/p&gt;

&lt;p&gt;Les variables qui ont des valeurs manquantes trés faible :
distance_to_target_goal : 17 valeurs manquantes (0.005559%)
angle_to_target_goal : 17 valeurs manquantes (0.005559%)
coordinates.x : 16 valeurs manquantes (0.005232%)
coordinates.y : 15 valeurs manquantes (0.004905%)
shot_angle_change : 10 valeurs manquantes (0.003270%)
result.secondaryType_smoothed_loo_encoded : 42 valeurs manquantes (0.013734%)&lt;/p&gt;

&lt;p&gt;Les variables qui ont des valeurs manquantes faible :
distance_from_last_event : 4169 valeurs manquantes (1.363247%)
prev_coordinates.x : 4157 valeurs manquantes (1.359323%)
prev_coordinates.y : 4156 valeurs manquantes (1.358996%)&lt;/p&gt;

&lt;p&gt;Pour la variable event_speed 3.53% de valeurs manquantes n’est pas négligeable, mais ce n’est pas non plus extrêmement élevé. Et vu qu’on a pas encore etudié l’importance de cette variable pour l’analyse de notre modèle on ne va pas la supprimer : 
event_speed : 10783 valeurs manquantes (3.525999%)&lt;/p&gt;

&lt;p&gt;Nous allons tester en premier temps, XGBoost missing parameter avant de passer à une autre solution.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Normaliser/standardiser les données :&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Vu que XGBoost, en tant qu’algorithme de gradient boosting, n’est généralement pas sensible à l’échelle des caractéristiques et gère bien les caractéristiques avec des échelles différentes, nous n’avons pas effectuer aucune opération pour normaliser nos données.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Déséquilibre des classes :&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Nous avons évaluer l’équilibre de nos étiquettes, et on a eu les résultats suivantes :&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;shot_or_goal&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;    &lt;span class=&quot;mi&quot;&gt;276782&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;29032&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;../assets/EvaluationClasses.png&quot; alt=&quot;Évaluation de l&apos;équilibre des classes&quot; /&gt;&lt;/p&gt;

&lt;p&gt;En regardant les résultats, on peut voir que la classe 0 a 276,782 occurrences tandis que la classe 1 a 29,032 occurrences. Cela indique un déséquilibre entre les deux classes, la classe 0 étant nettement plus fréquente que la classe 1. Donc on va tester en premier temps scale_pos_weight.&lt;/p&gt;

&lt;p&gt;Pour la prochaine étape on va essayer de tester plusieurs configurations du modéle XGBoost.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Configuration du modéle&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;5.1. Paramètres généraux&lt;/p&gt;

&lt;p&gt;Afin déterminer quel booster utiliser. On a utiliser la fonction cross_val_score de scikit-learn. C’est une fonction qui nous a permis d’effectuer une validation croisée k-fold, où l’ensemble de données est divisé en k sous-ensembles (folds), et le modèle est formé et évalué 5 fois, en utilisant à chaque fois un fold différent comme ensemble de test et les folds restants comme ensemble de formation. L’entrainement a été fait avec l’ensemble de données aprés l’utilisation de techniques comme SMOTE et ADASYN.&lt;/p&gt;

&lt;p&gt;Nous avons eu les résultats suivants :&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Evaluation&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gbtree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Mean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6928195654066989&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Mean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;precision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.18660854664748325&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Mean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6657768673121516&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Mean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.291506349546542&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Evaluation&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gblinear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Mean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6492350388355984&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Mean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;precision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.16804448927131777&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Mean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6822700170318263&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Mean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.26945364456039583&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Evaluation&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Mean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6928195654066989&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Mean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;precision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.18660854664748325&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Mean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6657768673121516&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Mean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.291506349546542&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;The&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;based&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cross&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;validation&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gbtree&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Evaluation&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.7136994588231447&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Precision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.18296119661825277&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Recall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5809671313027017&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;F1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.278283806619132&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;les-résultats-que-nous-avons-obtenus-montrent-que-le-modèle-gbtree-est-celui-qui-a-la-meilleure-performance-globale-avec-des-mesures-dévaluation-élevées-telles-que-laccuracy-la-précision-le-rappel-et-le-f1-score-dun-point-de-vue-global-il-semble-être-un-choix-solide&quot;&gt;Les résultats que nous avons obtenus montrent que le modèle gbtree est celui qui a la meilleure performance globale, avec des mesures d’évaluation élevées telles que l’accuracy, la précision, le rappel, et le F1-score. D’un point de vue global, il semble être un choix solide.&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;../assets/GoalRatebyDistanceBin.png&quot; alt=&quot;Histogramme du taux de buts par groupe de distance en pieds&quot; /&gt;			
&lt;img src=&quot;../assets/GoalRatebyDistanceBinExludEmptynet.png&quot; alt=&quot;Histogramme du taux de buts par groupe de distance en pieds&quot; /&gt;&lt;/p&gt;

&lt;p&gt;En regardant le taux de buts par groupe de distance en pieds, il est possible de voir une tendance que les tirs les plus dangereux semblent être ceux effectués près du filet. La recrudescence des buts à partir de la distance de 100 pieds est due aux buts dans les filets déserts et aux événements mal classés. Effectivement, comme peu de tirs sont effectués à cette distance quand le gardien en en position dans le but, le taux de buts à ces distances sont expliqués par les buts en filet désert. On peut réaliser dans la figure de droite en retirant ces buts que le taux de buts diminue plus on s’éloigne du filet.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/GoalRatebyAngleBin.png&quot; alt=&quot;Histogramme du taux de buts par angle par rapport au filet&quot; /&gt;&lt;/p&gt;

&lt;p&gt;En un simple coup d’œil, il est possible de voir que plus on s’éloigne de l’angle de 90 degré, moins les tirs sont efficaces pour marquer des buts comme le taux de buts diminue. Cependant, l’effet est moins marqué que celui de la distance et il y a un effet plateau entre 70 et 30 degrés où les taux sont similaires. À noter encore que les groupes d’angle sous les 90 degré représente les angles à gauche et à droite du gardien, alors l’importance d’être près du 90 degré ici est minimisée.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/EmptyNetvsNon-EmptyNet.png&quot; alt=&quot;Histogramme en transformation log des buts marqués en filet désert ou non&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ici, nous avons dû faire une transformation en base logarithmique pour mieux déceler et comparer les deux entités parce que la différence en termes de nombre d’événements entre les deux catégories est trop importante. Il est possible de voir que le nombre de buts en filet désert est assez constant à travers toutes les distances et dépasse le nombre de buts marqués avec un gardien présent à environ 70 pieds du filet. Il est possible de penser que les événements où un but est marqué à une distance plus grande que 100 pieds lorsque le gardien est présent sont rarissimes et qu’une partie d’entre eux ont des erreurs au niveau de l’enregistrement de leurs coordonnées dans le jeu de données initial.&lt;/p&gt;

&lt;p&gt;Pour identifier les événements qui étaient possiblement mal classés en termes de coordonnées, il suffisait d’utiliser l’intuition de nos connaissances de hockey et de celle acquise avec la visualisation des données en observant les buts réalisés avec un gardien présent à des distances plus hautes. Voici un exemple d’évènements repéré:	
0,2,2015-10-08T00:21:09Z,Toronto Maple Leafs,GOAL,-73.0,-1.0,Deflected,False,Power Play,James van Riemsdyk,Carey Price,2015020001,regular&lt;/p&gt;

&lt;p&gt;En 2015, en deuxième période, les Maple Leafs tiraient sur le but (89,0) et donc un tir dévié sur le power play provenait le plus probablement des coordonnées (73, -1). Comme on peut voir sur la photo prise d’une vidéo youtube d’un récapitulatif de la chaîne TVA sport, James van Riemsdyk est le joueur positionné directement devant le gardien Carey Price.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;blockquote&gt;
      &lt;blockquote&gt;
        &lt;blockquote&gt;
          &lt;blockquote&gt;
            &lt;blockquote&gt;
              &lt;p&gt;9acdaf782465def919acece561c245176ff86683&lt;/p&gt;
            &lt;/blockquote&gt;
          &lt;/blockquote&gt;
        &lt;/blockquote&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;p&gt;Cependant, lorsqu’on regarde le modèle gblinear, on remarque que bien que l’accuracy soit raisonnable, les mesures de précision, de rappel, et de F1-score sont significativement plus basses. Cela pourrait indiquer que le modèle linéaire généralisé (gblinear) ne capture peut-être pas aussi bien les relations complexes dans nos données par rapport au modèle basé sur les arbres (gbtree).&lt;/p&gt;

&lt;p&gt;5.2. Paramètres pour Tree Booster&lt;/p&gt;

&lt;p&gt;XGBoost fournit de nombreux hyperparamètres qui peuvent être ajustés pour améliorer les performances du modèle. Certains hyperparamètres importants sont :&lt;/p&gt;

&lt;p&gt;n_estimators : Le nombre de tours de boosting.
max_degree : La profondeur maximale de chaque arbre.
learning_rate : La taille de pas utilisée pour les mises à jour de poids.
subsample : La fraction d’échantillons à utiliser pour chaque cycle de boosting.
colsample_bytree : La fraction de fonctionnalités à utiliser pour chaque arbre.&lt;/p&gt;

&lt;p&gt;Expériance I : (param_dist avec une profondeur maximale plus faible et un taux d’apprentissage plus élevé) :&lt;/p&gt;

&lt;p&gt;«««&amp;lt; HEAD&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Best&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hyperparameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;subsample&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;colsample_bytree&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Performance du modèle sur les données de validation :&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.7113&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Precision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6147&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Recall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1881&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;F1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2880&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Accuracy : est d’environ 71,13 %. Cela signifie qu’environ 71,13 % des prédictions faites par le modèle sont correctes.&lt;/p&gt;

&lt;p&gt;Précision : la précision est d’environ 61,47 %. Cela signifie que lorsque le modèle prédit la classe positive, il est correct dans environ 61,47 % des cas.&lt;/p&gt;

&lt;p&gt;Rappel (sensibilité) : Dans notre cas, le rappel est d’environ 18,81 %. Cela signifie que le modèle ne capture qu’environ 18,81 % des cas positifs réels.&lt;/p&gt;

&lt;p&gt;Expériance II : (param_dist avec max_depth plus élevé et learning_rate plus bas) :&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Best&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hyperparameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;subsample&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;min_child_weight&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;colsample_bytree&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Performance du modèle sur les données de validation :&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8806&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Precision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1561&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Recall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2742&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;F1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1989&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Accuracy : est d’environ 88,06 %. Cela signifie qu’environ 88,06 % des prédictions faites par le modèle sont correctes.&lt;/p&gt;

&lt;p&gt;Précision : la précision est d’environ 15,61 %. Cela signifie que lorsque le modèle prédit la classe positive, il est correct dans environ 15,61 % des cas.&lt;/p&gt;

&lt;p&gt;Rappel (sensibilité) : Dans notre cas, le rappel est d’environ 19,89 %. Cela signifie que le modèle ne capture qu’environ 19,89% des cas positifs réels.&lt;/p&gt;

&lt;p&gt;Observations :&lt;/p&gt;

&lt;p&gt;Sur la base des deux expériences, il semble que la configuration de l’expérience 2 (max_depth plus élevé, learning_rate plus faible) ait donné de meilleurs résultats sur l’ensemble de validation. Voici quelques informations et ajustements potentiels :&lt;/p&gt;

&lt;p&gt;Expérience 1 :&lt;/p&gt;

&lt;p&gt;Avantages : Précision plus élevée, ce qui indique un taux de faux positifs plus faible.
Inconvénients : faible rappel, ce qui signifie un taux de faux négatifs plus élevé. Précision et score F1 modérés.&lt;/p&gt;

&lt;p&gt;Expérience 2 :&lt;/p&gt;

&lt;p&gt;Avantages : Précision et score F1 plus élevés, ce qui indique un bon équilibre entre la précision et le rappel.
Inconvénients : précision plus faible, ce qui peut entraîner un plus grand nombre de faux positifs.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   &lt;span class=&quot;n&quot;&gt;param_subsample&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;param_colsample_bytree&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;mean_score&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.939308&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.906488&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.960865&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.961295&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.961282&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.913751&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.961114&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.960965&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.904596&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.954664&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Best&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;subsample&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;colsample_bytree&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Best&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9612952029594501&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;5.3. Techniques avancées&lt;/p&gt;

&lt;p&gt;Pour améliorer encore les performances de notre modèle XGBoost, on a utiliser des techniques avancées telles que :&lt;/p&gt;

&lt;p&gt;Early Stopping : arrêtez l’entraînement lorsque l’erreur de validation ne s’améliore pas pendant un certain nombre de tours.&lt;/p&gt;

&lt;p&gt;reg_alpha et reg_lambda : Paramètres de régularisation L1 et L2 qui peuvent aider à prévenir le surajustement.&lt;/p&gt;

&lt;p&gt;gamma : Paramètre de régularisation qui contrôle si un nœud doit être scindé en fonction de la réduction de perte attendue après la scission.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   &lt;span class=&quot;n&quot;&gt;param_subsample&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;param_colsample_bytree&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;mean_score&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.939308&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.906488&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.960865&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.961295&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.961282&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.913751&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.961114&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.960965&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.904596&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;              &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;                     &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;    &lt;span class=&quot;mf&quot;&gt;0.954664&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Best&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;reg_lambda&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;reg_alpha&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;early_stopping_rounds&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Best&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9626456205377728&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Enfin, nous avons notre classificateur XGBoost avec des hyperparamètres choisis aprés l’application de RandomizedSearchCV.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        &lt;span class=&quot;n&quot;&gt;nthread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;scale_pos_weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;27&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;subsample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;colsample_bytree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;reg_lambda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;reg_alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;early_stopping_rounds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;eval_metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;logloss&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Les résultats trouvés :
&lt;img src=&quot;../assets/Q2XGBoostROC.png&quot; alt=&quot;Receiver Operating Characteristic&quot; /&gt;
&lt;img src=&quot;../assets/Q2XGBoost_G2.png&quot; alt=&quot;Goal Rate vs. Shot Probability Model Percentile&quot; /&gt;
&lt;img src=&quot;../assets/Q2XGBoost_G3.png&quot; alt=&quot;shap_corr_matCumulative Goal Proportion vs. Shot Probability Model Percentilerix&quot; /&gt;
&lt;img src=&quot;../assets/Q2XGBoost_G4.png&quot; alt=&quot;Reliability Diagram (Calibration Curve) for Model&quot; /&gt;
=======&lt;/p&gt;
&lt;h2 id=&quot;partie-3-modèles-de-base-1&quot;&gt;Partie 3: Modèles de base&lt;/h2&gt;

&lt;p&gt;La précision du modèle est de 90% d’accuracy pour un modèle de régression logistique de base ce qui me semble trop élevé pour un classifieur de base basé seulement sur la distance. Un problème que je vois pourrait être que le classifieur ne fait qu’utiliser le taux de buts par distance, qui diminue plus la distance augmente, pour faire sa prédiction. Comme les buts sont relativement rares, le modèle n’a qu’à prédire légèrement plus de buts que le taux de buts par distance pour avoir une performance adéquate. Cependant, ce type de modèle, si utilisé sur d’autres données va faire des erreurs par exemple s’il y a un tir effectué de très loin vers un filet désert, des tirs de la ligne bleue lors d’avantage numérique, d’autant plus à 5 contre 3 etc. De plus, si on veut un modèle de plus en plus précis en analysant plus de données, la composante binaire nous intéresse moins que la probabilité que le tir soit un but.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Image1.png&quot; alt=&quot;ROC curves for all the models&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Il est possible de voir qu’entre les caractéristiques de distance et d’angle, celle de distance est plus discriminante pour savoir si un tir sera un but ou non. Nous avions déjà développé cette intuition en regardant les graphiques de taux de buts par distance et par angle. Après 90 degrés, le taux de buts par angle frappe un plateau de 70 à 30 degrés tandis que le taux de buts par distance ne cesse de diminuer plus la distance augmente. On peut voir que lorsqu’on combine l’angle et la distance, le modèle performe légèrement mieux en terme de discrimination.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Image2.png&quot; alt=&quot;Graphique du taux de buts par la probabilité du modèle en percentile&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Il est possible de voir encore une fois la même tendance, c’est-à-dire que la prédiction par le modèle est meilleure en termes de percentile en considérant le taux de but par distance que par angle pour les mêmes raisons qu’évoqué plus tôt. Encore une fois le modèle combiné performe légèrement mieux que celui de la distance seul.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Image3.png&quot; alt=&quot;Graphique du taux de buts par la probabilité du modèle en percentile&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Il est possible de voir encore une fois la même tendance, c’est-à-dire que la prédiction par le modèle est meilleure en termes de percentile en considérant le taux de but par distance que par angle pour les mêmes raisons qu’évoqué plus tôt. Encore une fois le modèle combiné performe légèrement mieux que celui de la distance seul. Le modèle par angle offre un performance légèrement meilleure que le modèle aléatoire de base.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Image4.png&quot; alt=&quot;Graphique du taux de buts par la probabilité du modèle en percentile&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On voit qu’ajouter une variable pour que notre modèle soit plus précis fonctionne. Cependant, comme nous n’avons que fait des modèles de bases, nous atteignons à peine le 0,4 de probabilité prédite moyenne avec notre meilleur modèle, soit celui de la distance et de l’angle combiné. Il faudra très probablement inclure plus de caractéristiques plus complexes dans les prochaines étapes du projet pour faire des modèles se rapprochant de la ligne de la calibration parfaite.&lt;/p&gt;

&lt;h2 id=&quot;partie-3---ingéneries-des-charactéristiques&quot;&gt;Partie 3 - Ingéneries des charactéristiques&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;blockquote&gt;
      &lt;blockquote&gt;
        &lt;blockquote&gt;
          &lt;blockquote&gt;
            &lt;blockquote&gt;
              &lt;p&gt;9acdaf782465def919acece561c245176ff86683&lt;/p&gt;
            &lt;/blockquote&gt;
          &lt;/blockquote&gt;
        &lt;/blockquote&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;p&gt;On constate une petite amélioration au niveau de ROC par rapport au premier modéle, et on obsèrve aussi qu’au niveau du diagramme calibration notre modéle de la partie 2 s’éloigne de la ligne de calibration parfaite.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.comet.com/francis75/nhl-projectvf/cbc103876f724bc191f1090a1e6781c8&quot;&gt;XGBoostPartII&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;«««&amp;lt; HEAD
&lt;strong&gt;Question 3:&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Sélection des fonctionnalités :&lt;/p&gt;

&lt;p&gt;Un modèle XGBoost entraîné calcule automatiquement l’importance des fonctionnalités sur le problème de modélisation prédictive.&lt;/p&gt;

&lt;p&gt;Ces scores d’importance sont disponibles dans la variable membre d’importance des fonctionnalités du modèle entraîné. Nous avons pu imprimés directement comme suit :&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nf&quot;&gt;plot_importance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xgb_classifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Les caractéristiques ‘is_rebound’, ‘about.period’ sont les moins important dans la prédiction avec des F score respectivement 12, 13. Et les caractéristiques ‘coordinates.y’, ‘distance_to_target_goal’,’prev_result.eventTypeId’ avec des F score respectivement 457,337,320. Ce qui peut être justifiables pour prédire les buts dans un contexte de hockey.&lt;/p&gt;

&lt;p&gt;‘coordinates.y’ : La position y sur le terrain peut certainement avoir un impact sur la probabilité de marquer un but. Les tirs pris de positions plus avancées sur le terrain peuvent avoir des angles de tir différents et peuvent être plus difficiles à défendre.&lt;/p&gt;

&lt;p&gt;‘distance_to_target_goal’ : La distance au but est également une caractéristique importante. En général, les tirs pris de plus près ont une probabilité plus élevée de se transformer en but. Cependant, cela peut dépendre de divers facteurs, y compris la compétence du tireur.&lt;/p&gt;

&lt;p&gt;‘prev_result.eventTypeId’ : La nature du résultat précédent (par exemple, un tir réussi ou raté) peut également influencer les résultats futurs. Cela peut être une caractéristique informative pour capturer la dynamique du jeu.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Feature_importance.png&quot; alt=&quot;Feature_importance&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On a aussi utilisé la bibliothèque SHAP (SHapley Additive exPlanations) qui permet d’expliquer la sortie de tout modèle comme une somme de contributions de chaque fonction d’entrée, attribuant une valeur d’importance à chaque caractéristique pour chaque prédiction.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/ShapImportance.png&quot; alt=&quot;Shap Résultat&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Shap classe également les caractéristiques ‘is_rebound’, ‘about.period’, et ‘time_since_last_event’ parmi les moins importantes. En revanche, il accorde une importance significative aux caractéristiques ‘coordinates.y’, ‘distance_to_target_goal’, et ‘game_second’.&lt;/p&gt;

&lt;p&gt;Ensuite on a étudié l’effets d’interaction : pour observer si certaines caractéristiques ont tendance à interagir entre elles. Les effets d’interaction peuvent fournir des indications sur la manière dont les caractéristiques s’influencent mutuellement dans la prédiction. Les fortes corrélations peuvent indiquer des interactions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/shap_corr_matrix.png&quot; alt=&quot;shap_corr_matrix&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On constate que les caractéristiques “shot angle change”et “is rebound” ; 
ont une valeur de 0.97 dans le contexte d’une matrice de corrélation ce qui indique une forte corrélation négative entre ces deux variables. La corrélation négative suggère qu’il y a une relation linéaire inverse entre les deux variables : lorsque l’une augmente, l’autre diminue de manière proportionnelle.&lt;/p&gt;

&lt;p&gt;Plus précisément, une valeur de -0.97 indique une corrélation très forte et presque parfaite (en termes de magnitude) entre ces deux variables. Cela signifie que, dans votre ensemble de données, il y a une tendance très claire selon laquelle lorsque le “shot angle change” augmente, la probabilité que cela soit un “rebound” diminue fortement, et vice versa.&lt;/p&gt;

&lt;p&gt;Et les caractéristiques ‘prev_result.eventTypeId’ et “is rebound” ont une valeur de -0.75 ce qui suggère une relation inverse relativement forte entre ces deux variables. Cela signifie que, en général, lorsque ‘prev_result.eventTypeId’ augmente, la probabilité d’un “rebound” diminue, et vice versa.&lt;/p&gt;

&lt;p&gt;De manière similaire, une corrélation de 0.75 entre ‘prev_result.eventTypeId’ et “shot angle change” suggère une relation positive relativement forte. En d’autres termes, lorsque ‘prev_result.eventTypeId’ augmente, la valeur de “shot angle change” a tendance à augmenter également.&lt;/p&gt;

&lt;p&gt;Voici quelques interprétations possibles :&lt;/p&gt;

&lt;p&gt;‘prev_result.eventTypeId’ et “is rebound” : Il se peut que le type d’événement précédent ait une influence sur la probabilité qu’un tir soit un “rebound”. Par exemple, si le tir précédent a été arrêté par le gardien de but, il pourrait y avoir moins de chances qu’un tir suivant soit un “rebound”.&lt;/p&gt;

&lt;p&gt;‘prev_result.eventTypeId’ et “shot angle change” : La corrélation positive peut indiquer que certaines situations ou types d’événements antérieurs sont associés à des changements d’angle de tir. Par exemple, des événements spécifiques pourraient conduire à des positions de tir différentes, influençant ainsi l’angle du tir suivant.&lt;/p&gt;

&lt;p&gt;Pour traiter cela, nous avons envisager d’utiliser une technique de sélection de caractéristiques la régression LASSO (L1 regularization) qui favorise la sparsité en poussant certains coefficients vers zéro :&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Fit a LASSO regression model
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lasso_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Lasso&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
&lt;span class=&quot;n&quot;&gt;lasso_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train_resampled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train_resampled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Get selected features
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;selected_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train_resampled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lasso_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coef_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Use only selected features
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train_lasso&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train_resampled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;selected_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_val_lasso&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_val_loo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;selected_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_train_lasso&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Les résultats trouvés :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/Q3XGBoostROC.png&quot; alt=&quot;Receiver Operating Characteristic&quot; /&gt;
&lt;img src=&quot;../assets/Q3XGBoost_G2.png&quot; alt=&quot;Goal Rate vs. Shot Probability Model Percentile&quot; /&gt;
&lt;img src=&quot;../assets/Q3XGBoost_G3.png&quot; alt=&quot;shap_corr_matCumulative Goal Proportion vs. Shot Probability Model Percentilerix&quot; /&gt;
&lt;img src=&quot;../assets/Q3XGBoost_G4.png&quot; alt=&quot;Reliability Diagram (Calibration Curve) for Model&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On constate que les probabilités prédites par le modèle soient loin de la ligne de calibration du modéle de la partie 3 par rapport de la partie 2. Ainsi qu’une diminution de la valeur de ROC. Malgré les techniques testé, il faut investiguer pour améliorer la calibration de votre modèle.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.comet.com/francis75/nhl-projectvf/cbc103876f724bc191f1090a1e6781c8&quot;&gt;ExpérianceXGBoostPartIII&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;partie-6---on-a-essayé-de-faire-de-notre-mieux-avec-des-nouveaux-modèles&quot;&gt;Partie 6 - On a essayé de faire de notre mieux avec des nouveaux modèles&lt;/h2&gt;

&lt;h3 id=&quot;decisiontree-et-random-forest&quot;&gt;DecisionTree et Random Forest&lt;/h3&gt;

&lt;p&gt;Lien vers l’expérience de Decision Tree:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.comet.com/francis75/nhl-project/c63d0e82d14b4d2c8988f57cf26cf730?experiment-tab=panels&amp;amp;showOutliers=true&amp;amp;smoothing=0&amp;amp;xAxis=wall&quot;&gt;ExpérienceDecisionTree&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Lien vers Random forest:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.comet.com/francis75/nhl-project/f2d417d4484b4515b690f6a150862a03?experiment-tab=panels&amp;amp;showOutliers=true&amp;amp;smoothing=0&amp;amp;xAxis=wall&quot;&gt;ExpérienceRandomforest&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Pour les deux modèles, nous avons effectué une validation croisée sur 5 “fold” et stratifiée afin d’avoir autant d’échantillons de buts dans les “fold” de validation. Nous avons également fait une recherche d’hyperparamètres.&lt;/p&gt;

&lt;p&gt;Pour Decision Tree voici les paramètres utilisés:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;smote_tomek__sampling_strategy&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Different ratios of minority to majority class
&lt;/span&gt;   &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;classifier__max_depth&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Maximum depth of the tree
&lt;/span&gt;   &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;classifier__min_samples_split&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Minimum number of samples required to split an internal node
&lt;/span&gt;   &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;classifier__min_samples_leaf&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Minimum number of samples required to be at a leaf node
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Pour Random forest:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Parameter grid for GridSearchCV
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;randomforestclassifier__n_estimators&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Number of trees in the forest
&lt;/span&gt;   &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;randomforestclassifier__max_depth&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Maximum depth of the trees
&lt;/span&gt;   &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;randomforestclassifier__min_samples_leaf&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Minimum number of samples required at a leaf node
&lt;/span&gt;   &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;randomforestclassifier__class_weight&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;balanced&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;balanced_subsample&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Class weights
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Nettoyage et préparations des données&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Nous avons imputés les données avec la medianne pour les données numériques et la données la plus fréquente pour les données catégoriques.&lt;/p&gt;

&lt;p&gt;Ensuite, pour les données catégoriques, le codeur cible TargetEncoder de la librairie category_encoder est utiilisé avec un smoothing de 20. 
La technique d’échantillonnage SMOTE-Tomek sont appliqués à l’intérieur de chaque “fold” du processus de validation croisée, y compris à la fois les parties d’entraînement et de validation à l’intérieur de ce “fold”. Cependant, ils ne sont pas appliqués à l’ensemble du jeu de données en une seule fois. Ceci est une distinction importante pour éviter toute fuite de données.&lt;/p&gt;

&lt;p&gt;Dans le contexte de “GridSearchCV” avec un pipeline dans scikit-learn, chaque fold de la validation croisée est traité comme un processus d’entraînement et de validation distinct. Les étapes du pipeline (y compris le codage de la cible et l’échantillonnage SMOTE-Tomek) ne sont appliquées qu’à la partie d’entraînement de chaque fold. Ensuite, la partie de validation est transformée (mais pas ajustée) avec le codeur, et aucune échantillonnage n’est effectuée sur les données de validation (car l’échantillonnage n’est généralement pas effectué sur les données de validation/test).&lt;/p&gt;

&lt;p&gt;Voici ce qui se passe dans chaque fold de la validation croisée :&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Partie d’Entraînement du Fold&lt;/strong&gt;: Le codeur cible est ajusté sur la partie d’entraînement, puis utilisé pour transformer les données d’entraînement. Ensuite, la technique SMOTE-Tomek est appliquée aux données d’entraînement encodées. Le modèle est entraîné sur ces données encodées et échantillonnées.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Partie de Validation du Fold&lt;/strong&gt;: Le même codeur cible (ajusté sur la partie d’entraînement) est utilisé pour transformer la partie de validation. La technique SMOTE-Tomek n’est pas appliquée aux données de validation. Le modèle est ensuite évalué sur ces données de validation transformées.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;En procédant ainsi, le pipeline garantit que les données de validation restent invisibles et ne sont pas utilisées dans le processus d’ajustement du codeur ni de la technique SMOTE-Tomek, évitant ainsi toute fuite de données. C’est une pratique standard et recommandée lors de l’utilisation de pipelines avec des étapes de prétraitement dans scikit-learn.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Résultats&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Nous avons obtenus de très mauvais résultats pour Decision Tree, mais Random forest semble avoir mieux performé alors nous allons que montrer les figures de random forest:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/ROC_curve_RF.png&quot; alt=&quot;ROC_curve_RF&quot; /&gt;
&lt;img src=&quot;../assets/goal_rate_RF.png&quot; alt=&quot;goal_rate_RF&quot; /&gt;
&lt;img src=&quot;../assets/cumulative_proportion_RF.png&quot; alt=&quot;cumulative_proportion_RF&quot; /&gt;
&lt;img src=&quot;../assets/calibration_RF.png&quot; alt=&quot;calibration_RF&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Voici d’autres métriques importantes du random forest:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Fitting&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;folds&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;18&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;candidates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;totalling&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;90&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fits&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Best&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;randomforestclassifier__class_weight&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;balanced_subsample&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;randomforestclassifier__max_depth&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;randomforestclassifier__min_samples_leaf&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;randomforestclassifier__n_estimators&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;precision&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;recall&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;support&lt;/span&gt;

           &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.94&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.74&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.83&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;55357&lt;/span&gt;
           &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.19&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.59&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.29&lt;/span&gt;      &lt;span class=&quot;mi&quot;&gt;5806&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;                           &lt;span class=&quot;mf&quot;&gt;0.72&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;61163&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;macro&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.57&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.66&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.56&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;61163&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;weighted&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.87&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.72&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.78&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;61163&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;regression-logistique&quot;&gt;Regression logistique&lt;/h3&gt;

&lt;p&gt;Lien vers l’expérience: https://www.comet.com/francis75/nhl-project/3094395da1654feda8351b8caaf4f5e1?experiment-tab=panels&amp;amp;showOutliers=true&amp;amp;smoothing=0&amp;amp;xAxis=wall&lt;/p&gt;

&lt;p&gt;Dans les étapes suivantes de notre analyse. Les valeurs manquantes dans les colonnes 
numériques et catégorielles ont été traitées en utilisant des stratégies d’imputation appropriées. De plus, nous avons effectué la détection et la suppression des valeurs aberrantes, en veillant à ce que notre ensemble de données soit exempt de valeurs extrêmes qui pourraient avoir un impact négatif sur les performances du modèle. Pour améliorer la robustesse du modèle, nous avons appliqué une mise à l’échelle RobustScaling() aux caractéristiques numériques. Les caractéristiques catégorielles ont été soumises à un encodage, avec l’encodage cible et l’encodage ordinal utilisés pour traiter correctement les données catégorielles. Pour la sélection des caractéristiques, nous avons utilisé l’élimination récursive des caractéristiques (RFE) pour sélectionner un sous-ensemble de caractéristiques pertinentes. Passant ensuite à la sélection et à l’optimisation du modèle, nous avons mis en œuvre une recherche d’hyperparamètres en utilisant GridSearchCV pour identifier le modèle de régression logistique le plus performant.&lt;/p&gt;

&lt;p&gt;Voici les résultats obtenus:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/ROC_curve_LOGREG.png&quot; alt=&quot;ROC_curve_LOG&quot; /&gt;
Avec un ROC de 0.78&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/goal_rate_LOGREG.png&quot; alt=&quot;goal_rate_LOG&quot; /&gt;
&lt;img src=&quot;../assets/cumulative_proportion_LOGREG.png&quot; alt=&quot;cumulative_proportion_LOG&quot; /&gt;
&lt;img src=&quot;../assets/calibration_LOGREG.png&quot; alt=&quot;calibration_LOG&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Pour ce qui en est des métriques de performances avec le meilleur modèle obtenu, nous avons recueilli ces résultats:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Best&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;class_weight&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;balanced&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;n_jobs&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;penalty&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;l2&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;solver&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;saga&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;tol&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;precision&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;recall&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;support&lt;/span&gt;

           &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.97&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.69&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.80&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;45157&lt;/span&gt;
           &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.16&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.72&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.27&lt;/span&gt;      &lt;span class=&quot;mi&quot;&gt;3819&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;                           &lt;span class=&quot;mf&quot;&gt;0.69&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;48976&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;macro&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.56&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.70&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.53&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;48976&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;weighted&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.90&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.69&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.76&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;48976&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;conclusion-le-meilleur-modèle-est-le-random-forest&quot;&gt;Conclusion le meilleur modèle est le Random forest!&lt;/h3&gt;

&lt;p&gt;En effet celui-ci a un meilleur f1-score pour le macro-avg qui est la mesure qui nous intéresse le plus, car il prend en compte de façon égal les deux classes, ce qui est important, car même si nous avons beaucoup moins d’échantillon dans la classe 1 (BUT), c’est une moyenne qui prend en considération les f1-score des classes en donnant un poid égal aux deux.&lt;/p&gt;

&lt;h2 id=&quot;partie-7&quot;&gt;Partie 7&lt;/h2&gt;

&lt;h3 id=&quot;figures&quot;&gt;Figures&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Question 1:&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Résultat du test du modèle de la partie 5 XGBoost sur les donnés de la saison régulière :&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/P7ModeleXGBoostQ2G1.png&quot; alt=&quot;Receiver Operating Characteristic&quot; /&gt;
&lt;img src=&quot;../assets/P7ModeleXGBoostQ2G2.png&quot; alt=&quot;Goal Rate vs. Shot Probability Model Percentile&quot; /&gt;
&lt;img src=&quot;../assets/P7ModeleXGBoostQ2G3.png&quot; alt=&quot;shap_corr_matCumulative Goal Proportion vs. Shot Probability Model Percentilerix&quot; /&gt;
&lt;img src=&quot;../assets/P7ModeleXGBoostQ2G4.png&quot; alt=&quot;Reliability Diagram (Calibration Curve) for Model&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Résultat du test du modèle de la partie 6 (Random forest) de la saison  régulière :&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/ROC_curve_Log.png&quot; alt=&quot;Receiver Operating Characteristic2&quot; /&gt;
&lt;img src=&quot;../assets/goal_rate_rf_test.png&quot; alt=&quot;Goal Rate vs. Shot Probability Model Percentile2&quot; /&gt;
&lt;img src=&quot;../assets/cumulative_proportion_rf_test.png&quot; alt=&quot;shap_corr_matCumulative Goal Proportion vs. Shot Probability Model Percentilerix2&quot; /&gt;
&lt;img src=&quot;../assets/calibration_rf_test.png&quot; alt=&quot;Reliability Diagram (Calibration Curve) for Model2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Question 2:&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Résultat du test du modèle de la partie 5 XGBoost sur les donnés de la saison playoff :&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/P7ModeleXGBoostQ2G1.png&quot; alt=&quot;Receiver Operating Characteristic&quot; /&gt;
&lt;img src=&quot;../assets/P7ModeleXGBoostQ2G2.png&quot; alt=&quot;Goal Rate vs. Shot Probability Model Percentile&quot; /&gt;
&lt;img src=&quot;../assets/P7ModeleXGBoostQ2G3.png&quot; alt=&quot;shap_corr_matCumulative Goal Proportion vs. Shot Probability Model Percentilerix&quot; /&gt;
&lt;img src=&quot;../assets/P7ModeleXGBoostQ2G4.png&quot; alt=&quot;Reliability Diagram (Calibration Curve) for Model&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Résultat du test du modèle de la partie 6 (Random forest) de la saison playoff :&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/ROC_curve_RF_playoff.png&quot; alt=&quot;Receiver Operating Characteristic1&quot; /&gt;
&lt;img src=&quot;../assets/goal_rate_RF_playoff.png&quot; alt=&quot;Goal Rate vs. Shot Probability Model Percentile1&quot; /&gt;
&lt;img src=&quot;../assets/cumulative_proportion_RF_playoff.png&quot; alt=&quot;shap_corr_matCumulative Goal Proportion vs. Shot Probability Model Percentilerix1&quot; /&gt;
&lt;img src=&quot;../assets/calibration_RF_playoff.png&quot; alt=&quot;Reliability Diagram (Calibration Curve) for Model1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;discussion-&quot;&gt;Discussion :&lt;/h3&gt;

&lt;p&gt;Lorsqu’on compare les figures du ROC-AUC, on peut voir que les valeurs sont systématiquement plus basses pour XGBoost, dans le cas des deux saisons de l’ensemble de test par rapport à l’ensemble de validation.&lt;/p&gt;

&lt;p&gt;Voici les rapports de classification pour les deux saisons pour l’expérience du modèle Random Forest sur l’ensemble de données de test de la partie 6.
Si l’on compare les figures avec celles de la partie 6, ainsi que les valeurs de précision, recall et accuracy nous avons des valeurs avec très peu d’écart qu’avec l’ensemble de test. 
De plus, les valeurs des courves ROC-AUC sont similaires.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Classification&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;report&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;regular&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;season&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;precision&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;recall&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;support&lt;/span&gt;

           &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.94&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.73&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.82&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;47232&lt;/span&gt;
           &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.20&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.61&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.30&lt;/span&gt;      &lt;span class=&quot;mi&quot;&gt;5176&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;                           &lt;span class=&quot;mf&quot;&gt;0.72&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;52408&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;macro&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.57&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.67&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.56&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;52408&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;weighted&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.87&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.72&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.77&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;52408&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;Classification&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;report&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;playoff&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;season&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;precision&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;recall&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;support&lt;/span&gt;

           &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.95&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.76&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.84&lt;/span&gt;      &lt;span class=&quot;mi&quot;&gt;4866&lt;/span&gt;
           &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.18&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.54&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.26&lt;/span&gt;       &lt;span class=&quot;mi&quot;&gt;460&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;                           &lt;span class=&quot;mf&quot;&gt;0.74&lt;/span&gt;      &lt;span class=&quot;mi&quot;&gt;5326&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;macro&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.56&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.65&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.55&lt;/span&gt;      &lt;span class=&quot;mi&quot;&gt;5326&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;weighted&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg&lt;/span&gt;       &lt;span class=&quot;mf&quot;&gt;0.88&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.74&lt;/span&gt;      &lt;span class=&quot;mf&quot;&gt;0.79&lt;/span&gt;      &lt;span class=&quot;mi&quot;&gt;5326&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On peut observer, que les deux ont des performance très similaires, avec peu de différence entre toutes les valeurs. On peut conclure que le modèle généralise bien.&lt;/p&gt;

&lt;p&gt;Références :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://notebook.community/minesh1291/MachineLearning/xgboost/feature_importance_v1&quot;&gt;https://notebook.community/minesh1291/MachineLearning/xgboost/feature_importance_v1&lt;/a&gt;;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/&quot;&gt;https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/&lt;/a&gt;;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://xgboost.readthedocs.io/en/stable/tutorials/categorical.html&quot;&gt;https://xgboost.readthedocs.io/en/stable/tutorials/categorical.html&lt;/a&gt;;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 

</feed>
